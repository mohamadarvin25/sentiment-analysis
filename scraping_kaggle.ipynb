{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Play Store Review Scraper - Kaggle Version\n",
    "\n",
    "## Overview\n",
    "Scraping 10,000+ Indonesian app reviews from Google Play Store using parallel processing.\n",
    "\n",
    "**Features:**\n",
    "- ‚ö° Parallel scraping (optimized for Kaggle)\n",
    "- üìä Real-time progress tracking\n",
    "- üîÑ Auto-retry on failures\n",
    "- üíæ Save to CSV & JSON\n",
    "- üìà Detailed statistics\n",
    "\n",
    "**Target:** 10,000+ reviews in ~5-10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%time\n",
    "# Install required packages\n",
    "!pip install -q google-play-scraper\n",
    "\n",
    "print(\"‚úì Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google_play_scraper import Sort, reviews_all\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scraper Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuration\n",
    "TARGET_REVIEWS = 12000  # Target with buffer\n",
    "MAX_WORKERS = 6  # Parallel workers (Kaggle optimized)\n",
    "MAX_RETRIES = 3  # Retry attempts per app\n",
    "\n",
    "# App list - popular Indonesian apps\n",
    "APP_LIST = [\n",
    "    ('com.gojek.app', 'Gojek'),\n",
    "    ('com.tokopedia.tkpd', 'Tokopedia'),\n",
    "    ('com.shopee.id', 'Shopee'),\n",
    "    ('com.instagram.android', 'Instagram'),\n",
    "    ('com.whatsapp', 'WhatsApp'),\n",
    "    ('com.spotify.music', 'Spotify'),\n",
    "    ('com.netflix.mediaclient', 'Netflix'),\n",
    "    ('id.dana', 'Dana'),\n",
    "    ('com.traveloka.android', 'Traveloka'),\n",
    "    ('com.bukalapak.android', 'Bukalapak'),\n",
    "    ('com.lazada.android', 'Lazada'),\n",
    "    ('id.co.bri.brimo', 'BRI Mobile'),\n",
    "    ('com.dbs.id.digibank', 'digibank'),\n",
    "    ('com.LinkAja', 'LinkAja'),\n",
    "    ('com.ovo.id', 'OVO'),\n",
    "]\n",
    "\n",
    "REVIEWS_PER_APP = TARGET_REVIEWS // len(APP_LIST) + 200\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Target reviews: {TARGET_REVIEWS:,}\")\n",
    "print(f\"  Apps to scrape: {len(APP_LIST)}\")\n",
    "print(f\"  Reviews per app: ~{REVIEWS_PER_APP:,}\")\n",
    "print(f\"  Max workers: {MAX_WORKERS}\")\n",
    "print(f\"  Estimated time: ~5-10 minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def scrape_single_app(app_info, count=1000, max_retries=3):\n",
    "    \"\"\"\n",
    "    Scrape reviews from a single app with retry mechanism\n",
    "    \n",
    "    Args:\n",
    "        app_info: Tuple of (app_id, app_name)\n",
    "        count: Number of reviews to scrape\n",
    "        max_retries: Maximum retry attempts\n",
    "    \n",
    "    Returns:\n",
    "        Dict with scraping results\n",
    "    \"\"\"\n",
    "    app_id, app_name = app_info\n",
    "    \n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Scrape reviews\n",
    "            result = reviews_all(\n",
    "                app_id,\n",
    "                sleep_milliseconds=0,\n",
    "                lang='id',\n",
    "                country='id',\n",
    "                sort=Sort.NEWEST\n",
    "            )\n",
    "            \n",
    "            # Limit to requested count\n",
    "            result = result[:count]\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            return {\n",
    "                'app_id': app_id,\n",
    "                'app_name': app_name,\n",
    "                'reviews': result,\n",
    "                'count': len(result),\n",
    "                'success': True,\n",
    "                'elapsed_time': elapsed,\n",
    "                'speed': len(result) / elapsed if elapsed > 0 else 0\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(attempt * 2)  # Exponential backoff\n",
    "            else:\n",
    "                return {\n",
    "                    'app_id': app_id,\n",
    "                    'app_name': app_name,\n",
    "                    'reviews': [],\n",
    "                    'count': 0,\n",
    "                    'success': False,\n",
    "                    'error': str(e)\n",
    "                }\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def scrape_parallel(app_list, reviews_per_app, max_workers=6):\n",
    "    \"\"\"\n",
    "    Scrape multiple apps in parallel\n",
    "    \n",
    "    Args:\n",
    "        app_list: List of (app_id, app_name) tuples\n",
    "        reviews_per_app: Number of reviews per app\n",
    "        max_workers: Number of parallel workers\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (all_reviews, results_summary)\n",
    "    \"\"\"\n",
    "    all_reviews = []\n",
    "    results = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STARTING PARALLEL SCRAPING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_app = {\n",
    "            executor.submit(scrape_single_app, app_info, reviews_per_app): app_info \n",
    "            for app_info in app_list\n",
    "        }\n",
    "        \n",
    "        # Progress bar\n",
    "        with tqdm(total=len(app_list), desc=\"üì± Scraping apps\", unit=\"app\") as pbar:\n",
    "            for future in as_completed(future_to_app):\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                \n",
    "                if result['success']:\n",
    "                    all_reviews.extend(result['reviews'])\n",
    "                    pbar.set_postfix({\n",
    "                        'collected': f\"{len(all_reviews):,}\",\n",
    "                        'success': sum(1 for r in results if r['success']),\n",
    "                        'failed': sum(1 for r in results if not r['success'])\n",
    "                    })\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úì Scraping completed in {total_time:.2f}s ({total_time/60:.2f} minutes)\")\n",
    "    print(f\"‚úì Total reviews collected: {len(all_reviews):,}\")\n",
    "    print(f\"‚úì Average speed: {len(all_reviews)/total_time:.1f} reviews/second\")\n",
    "    \n",
    "    return all_reviews, results\n",
    "\n",
    "print(\"‚úì Scraping functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start Scraping üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "# Run parallel scraping\n",
    "all_reviews, results = scrape_parallel(\n",
    "    app_list=APP_LIST,\n",
    "    reviews_per_app=REVIEWS_PER_APP,\n",
    "    max_workers=MAX_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scraping Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SCRAPING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "successful_apps = [r for r in results if r['success']]\n",
    "failed_apps = [r for r in results if not r['success']]\n",
    "\n",
    "print(f\"Total apps scraped: {len(results)}\")\n",
    "print(f\"Successful: {len(successful_apps)}\")\n",
    "print(f\"Failed: {len(failed_apps)}\")\n",
    "print(f\"Total reviews: {len(all_reviews):,}\")\n",
    "print(f\"Target achieved: {'‚úì YES' if len(all_reviews) >= 10000 else '‚úó NO'}\")\n",
    "\n",
    "if failed_apps:\n",
    "    print(f\"\\n‚ö†Ô∏è  Failed apps:\")\n",
    "    for app in failed_apps:\n",
    "        print(f\"  - {app['app_name']}: {app.get('error', 'Unknown error')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Per-app breakdown\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-APP BREAKDOWN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort by review count\n",
    "sorted_results = sorted(results, key=lambda x: x['count'], reverse=True)\n",
    "\n",
    "print(f\"{'App Name':<25} {'Reviews':<10} {'Time (s)':<10} {'Speed (rev/s)':<15} {'Status'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for result in sorted_results:\n",
    "    status = \"‚úì\" if result['success'] else \"‚úó\"\n",
    "    time_str = f\"{result.get('elapsed_time', 0):.2f}\" if result['success'] else \"N/A\"\n",
    "    speed_str = f\"{result.get('speed', 0):.1f}\" if result['success'] else \"N/A\"\n",
    "    \n",
    "    print(f\"{result['app_name']:<25} {result['count']:<10,} {time_str:<10} {speed_str:<15} {status}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert to DataFrame\n",
    "print(\"Converting to DataFrame...\")\n",
    "\n",
    "df = pd.DataFrame(all_reviews)\n",
    "\n",
    "# Select and rename relevant columns\n",
    "if len(df) > 0:\n",
    "    columns_to_keep = [\n",
    "        'reviewId',\n",
    "        'userName', \n",
    "        'content',\n",
    "        'score',\n",
    "        'at',\n",
    "        'replyContent',\n",
    "        'appVersion',\n",
    "        'thumbsUpCount'\n",
    "    ]\n",
    "    \n",
    "    df = df[columns_to_keep]\n",
    "    df.columns = [\n",
    "        'review_id',\n",
    "        'username',\n",
    "        'review_text',\n",
    "        'rating',\n",
    "        'date',\n",
    "        'reply',\n",
    "        'app_version',\n",
    "        'helpful_count'\n",
    "    ]\n",
    "    \n",
    "    print(f\"‚úì DataFrame created with {len(df):,} rows\")\n",
    "    print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No reviews collected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Basic info\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# First few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Statistics\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(f\"Total reviews: {len(df):,}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Unique users: {df['username'].nunique():,}\")\n",
    "print(f\"Average review length: {df['review_text'].str.len().mean():.1f} characters\")\n",
    "print(f\"Missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Rating distribution\n",
    "print(\"\\nRating Distribution:\")\n",
    "print(df['rating'].value_counts().sort_index())\n",
    "\n",
    "# Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Rating distribution\n",
    "df['rating'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Rating Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Rating')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Review length distribution\n",
    "review_lengths = df['review_text'].str.len()\n",
    "axes[1].hist(review_lengths, bins=50, color='lightcoral', edgecolor='black')\n",
    "axes[1].set_title('Review Length Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Characters')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].axvline(review_lengths.mean(), color='red', linestyle='--', label=f'Mean: {review_lengths.mean():.1f}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save to CSV\n",
    "csv_filename = 'playstore_reviews.csv'\n",
    "df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "print(f\"‚úì Saved to {csv_filename}\")\n",
    "\n",
    "# Save to JSON\n",
    "json_filename = 'playstore_reviews.json'\n",
    "with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_reviews, f, ensure_ascii=False, indent=2, default=str)\n",
    "print(f\"‚úì Saved to {json_filename}\")\n",
    "\n",
    "# File sizes\n",
    "import os\n",
    "csv_size = os.path.getsize(csv_filename) / 1024 / 1024\n",
    "json_size = os.path.getsize(json_filename) / 1024 / 1024\n",
    "\n",
    "print(f\"\\nFile sizes:\")\n",
    "print(f\"  CSV:  {csv_size:.2f} MB\")\n",
    "print(f\"  JSON: {json_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Download Files (For Kaggle)\n",
    "\n",
    "Click on the **Output** tab on the right sidebar, then click the download button for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verify files exist\n",
    "import os\n",
    "\n",
    "files_to_check = ['playstore_reviews.csv', 'playstore_reviews.json']\n",
    "\n",
    "print(\"Files ready for download:\")\n",
    "for filename in files_to_check:\n",
    "    if os.path.exists(filename):\n",
    "        size = os.path.getsize(filename) / 1024 / 1024\n",
    "        print(f\"  ‚úì {filename} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ‚úó {filename} (not found)\")\n",
    "\n",
    "print(\"\\nüì• Go to Output tab ‚Üí Click download button\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Quick Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample reviews\n",
    "print(\"Sample reviews:\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "for idx in df.sample(5).index:\n",
    "    row = df.loc[idx]\n",
    "    print(f\"Rating: {row['rating']} ‚≠ê\")\n",
    "    print(f\"Review: {row['review_text'][:150]}...\")\n",
    "    print(f\"Date: {row['date']}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SCRAPING COMPLETE! üéâ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total reviews collected: {len(df):,}\")\n",
    "print(f\"Target (10,000): {'‚úì ACHIEVED' if len(df) >= 10000 else '‚úó NOT ACHIEVED'}\")\n",
    "print(f\"\")\n",
    "print(f\"Files saved:\")\n",
    "print(f\"  1. playstore_reviews.csv\")\n",
    "print(f\"  2. playstore_reviews.json\")\n",
    "print(f\"\")\n",
    "print(f\"Next steps:\")\n",
    "print(f\"  1. Download files from Output tab\")\n",
    "print(f\"  2. Upload to your project\")\n",
    "print(f\"  3. Run training notebook\")\n",
    "print(f\"\")\n",
    "print(f\"Good luck with your submission! üöÄ\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
